#version 450

#extension GL_KHR_shader_subgroup_arithmetic : enable
#extension GL_KHR_memory_scope_semantics : enable
// #extension GL_EXT_shader_atomic_float : enable
#extension GL_KHR_shader_subgroup_vote : enable
#extension GL_KHR_shader_subgroup_ballot : enable
#pragma use_vulkan_memory_model

#define monoid float

layout(constant_id = 0) const uint GROUP_SIZE = 1;
layout(constant_id = 1) const uint SUBGROUP_SIZE = 1;
layout(constant_id = 2) const uint ROWS = 1;
const uint PARTITION_SIZE = GROUP_SIZE * ROWS;
const uint SUBGROUP_COUNT = (GROUP_SIZE + SUBGROUP_SIZE - 1) / SUBGROUP_SIZE;
layout(local_size_x_id = 0, local_size_y = 1, local_size_z = 1) in;

#define STATE_NO_AGGREGATE 0u
#define STATE_AGGREGATE 1u
#define STATE_PREFIX 2u
#define STATE_DONT_CARE 3u

struct PartitionDescriptor {
    monoid aggregate;
    monoid prefix;
    uint state;
};

layout(set = 0, binding = 0) readonly buffer in_values {
    monoid values[];
};

layout(set = 0, binding = 1) writeonly buffer out_inclusive_prefix_sum {
    monoid average;
    monoid prefix_sum[];
};

layout(set = 0, binding = 2) queuefamilycoherent buffer parition_descriptors {
    uint atomicWorkIDCounter;
    PartitionDescriptor partitions[];
};

layout(push_constant) uniform PushConstant {
    uint size;
} pc;

#define LOOK_BACK_STATE_SPIN 1u
#define LOOK_BACK_STATE_DONE 0u

shared uint lookBackState;
shared uint groupID;
shared monoid partPrefix;
shared monoid scratch[GROUP_SIZE];

#define ATOMIC_LOOK_BACK_STATE
#define ATOMIC_PARTITION_STATE

#define PARALLEL_LOOK_BACK

void main(void) {
  return;
    monoid local[ROWS];

    const uint invocID = gl_LocalInvocationID.x;
    const uint subInvocID = gl_SubgroupInvocationID.x;
    const uint subgroupID = gl_SubgroupID.x;
    const uint subgroupCount = gl_NumSubgroups.x;
    const uint subgroupSize = gl_SubgroupSize.x;
    const uint lookBackMaxStepSize = min(subgroupSize, 32);
    if (invocID == 0) {
        groupID = atomicAdd(atomicWorkIDCounter, 1);
    }
    controlBarrier(gl_ScopeWorkgroup, gl_ScopeWorkgroup, gl_StorageSemanticsShared, gl_SemanticsAcquireRelease);

    uint partID = groupID;
    uint ix = partID * PARTITION_SIZE + invocID * ROWS;
    // uint itemID = partID * PARTITION_SIZE + invocID * ROWS;
    bool seqInvoc = invocID == gl_WorkGroupSize.x - 1;
    bool seqSubgroup = subgroupID == subgroupCount - 1;

    // 1. Step calculate group aggregate
    local[0] = values[ix];
    for (uint i = 1; i < ROWS; ++i) {
        local[i] = local[i - 1] + values[ix + i];
    }
    monoid agg = local[ROWS - 1];

    scratch[invocID] = agg;

    for (uint shift = 1; shift <= (GROUP_SIZE >> 1); shift <<= 1) {
        barrier();
        // controlBarrier(gl_ScopeWorkgroup, gl_ScopeWorkgroup, gl_StorageSemanticsShared, gl_SemanticsAcquireRelease);
        if (invocID >= shift) {
            monoid other = scratch[invocID - shift];
            agg = agg + other;
        }
        barrier();
        // controlBarrier(gl_ScopeWorkgroup, gl_ScopeWorkgroup, gl_StorageSemanticsShared, gl_SemanticsAcquireRelease);
        scratch[invocID] = agg;
    }

    // 2. Publish Aggregate and state
    // 2.1 Publish aggregate
    if (gl_LocalInvocationID.x == gl_WorkGroupSize.x - 1) {
        partitions[partID].aggregate = agg;
        if (partID == 0) {
            partitions[partID].prefix = agg;
        }
    }

    // memoryBarrierBuffer();

    if (gl_LocalInvocationID.x == gl_WorkGroupSize.x - 1) {
        uint state = STATE_AGGREGATE;
        if (partID == 0) {
            state = STATE_PREFIX;
        }
        atomicStore(partitions[partID].state, state, gl_ScopeQueueFamily,
            gl_StorageSemanticsBuffer, gl_SemanticsRelease);
    }

    monoid exclusive = 0;
    if (partID != 0) {
        uint lookBackIndex = partID - 1;
        lookBackState = LOOK_BACK_STATE_SPIN;
        while (true) {
            uint lookState;
            if (gl_LocalInvocationID.x == gl_WorkGroupSize.x - 1) {
                lookState = atomicLoad(partitions[lookBackIndex].state, gl_ScopeQueueFamily,
                        gl_StorageSemanticsBuffer, gl_SemanticsAcquire | gl_SemanticsMakeVisible);
                if (lookState == STATE_AGGREGATE) {
                    exclusive += partitions[lookBackIndex].aggregate;
                    lookBackIndex--;
                    lookBackState = LOOK_BACK_STATE_SPIN;
                } else if (lookState == STATE_PREFIX) {
                    exclusive += partitions[lookBackIndex].prefix;
                    lookBackState = LOOK_BACK_STATE_DONE;
                } else if (lookBackState == STATE_NO_AGGREGATE) {
                    lookBackState = LOOK_BACK_STATE_SPIN;
                }
            }
            barrier();
            lookState = lookBackState;
            if (lookState == LOOK_BACK_STATE_DONE) {
                break;
            }
        }

        if (gl_LocalInvocationID.x == gl_WorkGroupSize.x - 1) {
            partPrefix = exclusive;
            partitions[partID].prefix = exclusive + agg;
        }

        controlBarrier(gl_ScopeWorkgroup, gl_ScopeQueueFamily, gl_StorageSemanticsBuffer | gl_StorageSemanticsShared,
            gl_SemanticsAcquireRelease);

        if (gl_LocalInvocationID.x == gl_WorkGroupSize.x - 1) {
            atomicStore(partitions[partID].state, STATE_PREFIX,
                gl_ScopeQueueFamily, gl_StorageSemanticsBuffer, gl_SemanticsRelease | gl_SemanticsMakeAvailable);
        }else {
          exclusive = partPrefix;
        }
    }

    // Compute partition inclusive prefix sum
    monoid row = exclusive;
    if (invocID > 0) {
        monoid other = scratch[invocID - 1];
        row = row + other;
    }
    for (uint i = 0; i < ROWS; ++i) {
        monoid m = row + local[i];
        prefix_sum[ix + i] = m;
    }

    if (partID == gl_NumWorkGroups.x - 1) {
        if (gl_LocalInvocationID.x == GROUP_SIZE - 1) {
            monoid sum = row + local[ROWS - 1];
            average = sum / pc.size;
        }
    }
}
