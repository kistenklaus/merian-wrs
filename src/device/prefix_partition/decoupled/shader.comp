#version 460

#extension GL_KHR_shader_subgroup_arithmetic : enable
#extension GL_KHR_memory_scope_semantics : enable
// #extension GL_EXT_shader_atomic_float : enable
#extension GL_KHR_shader_subgroup_vote : enable
#extension GL_KHR_shader_subgroup_ballot : enable
#pragma use_vulkan_memory_model

layout(local_size_x_id = 0, local_size_y = 1, local_size_z = 1) in;

layout(constant_id = 0) const uint WORKGROUP_SIZE = 1;
layout(constant_id = 1) const uint SUBGROUP_SIZE = 32;
layout(constant_id = 2) const uint ROWS = 1;
layout(constant_id = 3) const uint PARALLEL_LOOKBACK_DEPTH = 32;

const uint PARTITION_SIZE = WORKGROUP_SIZE * ROWS;
const uint SUBPARTITION_SIZE = SUBGROUP_SIZE * ROWS;
const uint MAX_NUMBER_OF_SUBGROUPS = (WORKGROUP_SIZE + SUBGROUP_SIZE - 1) / SUBGROUP_SIZE;

layout(set = 0, binding = 0) readonly buffer inElements {
    float weights[];
} g_weights;

layout(set = 0, binding = 1) readonly buffer in_pivot {
    float pivot;
} g_pivot;

layout(set = 0, binding = 3) writeonly buffer out_stat {
    uint heavyCount;
} g_stat;

layout(set = 0, binding = 4) writeonly buffer out_partition {
    uint heavyLight[];
} g_partition;

layout(set = 0, binding = 5) writeonly buffer out_prefix {
    float heavyLight[];
} g_prefix;

#ifdef WRITE_PARTITION_ELEMENTS
layout(set = 0, binding = 6) writeonly buffer out_partitionElements {
    float heavyLight[];
} g_partitionElements;
#endif

#define state_t uint
#define STATE_NOT_READY 0u
#define STATE_AGGREGATE_PUBLISHED 1u
#define STATE_PREFIX_PUBLISHED 2u

struct DecoupledState {
    uint heavyCount;
    uint heavyCountInclusivePrefix;
    float heavyAggregate;
    float lightAggregate;
    float heavyPrefix;
    float lightPrefix;
    state_t state;
};

layout(set = 0, binding = 2) volatile buffer DecoupledStates {
    uint counter;
    DecoupledState partitions[];
} g_states;

layout(push_constant) uniform PushConstant {
    uint N;
} pc;

#define lbstate_t uint
#define LOOKBACK_STATE_SPIN 1u
#define LOOKBACK_STATE_DONE 0u

shared uint sh_lookBackState;
shared uint sh_partID;

shared vec2 sh_subgroupPrefix[MAX_NUMBER_OF_SUBGROUPS];
shared uint sh_subgroupHeavyCount[MAX_NUMBER_OF_SUBGROUPS];

shared vec2 sh_exclusive;
shared uint sh_exclusiveCount;

float pivot;
uint N;

float localWeights[ROWS];
vec2 localPrefix[ROWS];
uint localExclusiveHeavyCount[ROWS];

struct WorkgroupAggregate {
    vec2 weightAgg;
    uint heavyCount;
};

WorkgroupAggregate computeLocalPrefixSum(in uint base, in uint N) {
    for (uint i = 0; i < ROWS; ++i) {
        uint index = base + i * SUBGROUP_SIZE;
        if (index < N) {
            localWeights[i] = g_weights.weights[index];
        } else {
            localWeights[i] = 0;
        }
    }

    uvec4 ballot = subgroupBallot(base < N);
    uint lastInvoc = subgroupBallotFindMSB(ballot);

    uint localHeavyCount = 0;
    for (uint i = 0; i < ROWS; ++i) {
        const float w = localWeights[i];
        const bool b = w > pivot;
        vec2 v;
        if (b) {
            v = vec2(w, 0);
        } else {
            v = vec2(0, w);
        }
        localPrefix[i] = subgroupInclusiveAdd(v);

        uvec4 isHeavyBallot = subgroupBallot(b);
        localExclusiveHeavyCount[i] = subgroupBallotExclusiveBitCount(isHeavyBallot) + localHeavyCount;
        localHeavyCount += subgroupBallotBitCount(isHeavyBallot);
    }

    for (uint i = 1; i < ROWS; ++i) {
        localPrefix[i] += subgroupBroadcast(localPrefix[i - 1], lastInvoc);
    }

    if (gl_SubgroupInvocationID.x == lastInvoc) {
        sh_subgroupPrefix[gl_SubgroupID] = localPrefix[ROWS - 1];
        sh_subgroupHeavyCount[gl_SubgroupID] = localHeavyCount;
    }

    vec2 exclusivePrefix;
    vec2 weightAgg = vec2(0, 0);
    uint exclusiveHeavyCount;
    uint heavyCount = 0;

    if (SUBGROUP_SIZE < MAX_NUMBER_OF_SUBGROUPS) {
        // for (uint shift = 1; shift <= MAX_NUMBER_OF_SUBGROUPS; shift <<= 1) {
        //     barrier();
        //     if (gl_LocalInvocationID.x >= shift) {
        //         const uint ix = gl_LocalInvocationID.x - shift;
        //         sh_subgroupPrefix[gl_LocalInvocationID.x] +=
        //             sh_subgroupPrefix[ix];
        //         sh_subgroupHeavyCount[gl_LocalInvocationID.x] +=
        //             sh_subgroupHeavyCount[ix];
        //     }
        // }
        // barrier();
        // exclusivePrefix = (gl_SubgroupID > 0) ? sh_subgroupPrefix[gl_SubgroupID - 1] : vec2(0.0f, 0.0f);
        // exclusiveHeavyCount = (gl_SubgroupID > 0) ? sh_subgroupHeavyCount[gl_SubgroupID - 1] : 0;
        // weightAgg = sh_subgroupPrefix[MAX_NUMBER_OF_SUBGROUPS - 1];
        // heavyCount = sh_subgroupHeavyCount[MAX_NUMBER_OF_SUBGROUPS - 1];
    } else {
        barrier();
        if (gl_SubgroupID == 0) {
            if (gl_SubgroupInvocationID < MAX_NUMBER_OF_SUBGROUPS) {
                uint ix = gl_SubgroupInvocationID;
                vec2 groupSum = sh_subgroupPrefix[ix];
                uint groupHeavyCount = sh_subgroupHeavyCount[ix];
                vec2 groupInclusivePrefix = subgroupInclusiveAdd(groupSum);
                uint groupInclusiveHeavyCount = subgroupInclusiveAdd(groupHeavyCount);
                sh_subgroupPrefix[ix] = groupInclusivePrefix;
                sh_subgroupHeavyCount[ix] = groupInclusiveHeavyCount;
            }
            subgroupBarrier();
        }
        barrier();
        if (gl_SubgroupID > 0) {
            exclusivePrefix = sh_subgroupPrefix[gl_SubgroupID - 1];
            exclusiveHeavyCount = sh_subgroupHeavyCount[gl_SubgroupID - 1];
        } else {
            exclusivePrefix = vec2(0, 0);
            exclusiveHeavyCount = 0;
        }

        weightAgg = sh_subgroupPrefix[MAX_NUMBER_OF_SUBGROUPS - 1];
        heavyCount = sh_subgroupHeavyCount[MAX_NUMBER_OF_SUBGROUPS - 1];
    }

    for (uint i = 0; i < ROWS; ++i) {
        localPrefix[i] += exclusivePrefix;
        localExclusiveHeavyCount[i] += exclusiveHeavyCount;
    }

    WorkgroupAggregate agg;
    agg.weightAgg = weightAgg;
    agg.heavyCount = heavyCount;

    return agg;
}

bool ballotIsZero(in uvec4 ballot) {
    return (ballot.x | ballot.y | ballot.z | ballot.w) == 0;
}

// see https://research.nvihttps://research.nvidia.com/publication/2016-03_single-pass-parallel-prefix-scan-decoupled-look-backdia.com/publication/2016-03_single-pass-parallel-prefix-scan-decoupled-look-back for the
// original paper by NVIDIA.
struct ExclusivePrefix {
    vec2 prefix;
    uint heavyCount;
};

ExclusivePrefix decoupledLookback(in uint partID, in WorkgroupAggregate aggregate) {
    // ================ Publish aggregate & state =====================
    if (gl_LocalInvocationID.x == gl_WorkGroupSize.x - 1) {
        // Non atomic write to coherent values.
        g_states.partitions[partID].heavyAggregate = aggregate.weightAgg.x;
        g_states.partitions[partID].lightAggregate = aggregate.weightAgg.y;
        g_states.partitions[partID].heavyCount = aggregate.heavyCount;
        state_t state = STATE_AGGREGATE_PUBLISHED;
        if (partID == 0) {
            g_states.partitions[partID].heavyPrefix = aggregate.weightAgg.x;
            g_states.partitions[partID].lightPrefix = aggregate.weightAgg.y;
            g_states.partitions[partID].heavyCountInclusivePrefix = aggregate.heavyCount;
            state = STATE_PREFIX_PUBLISHED;
        }
        // This atomicStore creates a *happens-before* relationship
        // with following atomicLoads, further the atomic release semantics
        // ensures that all coherent writes before the release operation are visible
        // after a atomic acquire operation of that value.
        // NOTE: gl_SemanticsMakeAvailable is only required if aggregate and prefix
        // are stored in a seperate storage buffer.
        atomicStore(g_states.partitions[partID].state, state, gl_ScopeQueueFamily,
            gl_StorageSemanticsBuffer, gl_SemanticsRelease);
    }
    // ================ Decoupled lookback ==================
    vec2 exclusive = vec2(0, 0);
    uint exclusiveCount = 0;
    if (partID != 0) {
        if (gl_SubgroupID == 0) {
            uint lookBackBase = partID - 1;

            while (true) {
                bool invocActive = gl_SubgroupInvocationID <= lookBackBase && gl_SubgroupInvocationID < PARALLEL_LOOKBACK_DEPTH;

                state_t predecessorState;
                bool done = false;
                if (invocActive) {
                    uint lookBackIdx = lookBackBase - gl_SubgroupInvocationID;
                    predecessorState = atomicLoad(g_states.partitions[lookBackIdx].state,
                            gl_ScopeQueueFamily, gl_StorageSemanticsBuffer, gl_SemanticsAcquire);

                    const bool notReady = predecessorState == STATE_NOT_READY;
                    const uvec4 notReadyBallot = subgroupBallot(notReady);
                    uint steps;
                    if (ballotIsZero(notReadyBallot)) {
                        done = predecessorState == STATE_PREFIX_PUBLISHED;
                        const uvec4 doneBallot = subgroupBallot(done);
                        if (ballotIsZero(doneBallot)) {
                            steps = min(PARALLEL_LOOKBACK_DEPTH, lookBackBase);
                        } else {
                            const uint stepsUntilPrefix = subgroupBallotFindLSB(doneBallot) + 1;
                            steps = stepsUntilPrefix;
                        }
                    } else {
                        done = false;
                        const uint stepsUntilNotReady = subgroupBallotFindLSB(notReadyBallot) + 1;
                        steps = stepsUntilNotReady - 1;
                    }
                    if (gl_SubgroupInvocationID.x < steps) {
                        vec2 acc;
                        uint accCount;
                        if (done) {
                            acc = vec2(g_states.partitions[lookBackIdx].heavyPrefix, g_states.partitions[lookBackIdx].lightPrefix);
                            accCount = g_states.partitions[lookBackIdx].heavyCountInclusivePrefix;
                        } else {
                            acc = vec2(g_states.partitions[lookBackIdx].heavyAggregate, g_states.partitions[lookBackIdx].lightAggregate);
                            accCount = g_states.partitions[lookBackIdx].heavyCount;
                        }
                        acc = subgroupAdd(acc);
                        accCount = subgroupAdd(accCount);
                        if (subgroupElect()) {
                            lookBackBase -= steps;
                            exclusive += acc;
                            exclusiveCount += accCount;
                        }
                    }
                }
                if (subgroupAny(done)) {
                    break;
                }
                lookBackBase = subgroupBroadcastFirst(lookBackBase);
            }
            if (subgroupElect()) {
                vec2 inclusive = exclusive + aggregate.weightAgg;
                uint inclusiveCount = exclusiveCount + aggregate.heavyCount;
                g_states.partitions[partID].heavyPrefix = inclusive.x;
                g_states.partitions[partID].lightPrefix = inclusive.y;
                g_states.partitions[partID].heavyCountInclusivePrefix = inclusiveCount;
                sh_exclusive = exclusive;
                sh_exclusiveCount = exclusiveCount;
                atomicStore(g_states.partitions[partID].state, STATE_PREFIX_PUBLISHED,
                    gl_ScopeQueueFamily, gl_StorageSemanticsBuffer,
                    gl_SemanticsRelease | gl_SemanticsMakeAvailable);
            }
        }
        // WTF NVIDIA Driver? (Probably some bugs related to Independent Thread Scheduling)
        subgroupBarrier();
        controlBarrier(gl_ScopeWorkgroup, gl_ScopeWorkgroup, gl_StorageSemanticsShared, gl_SemanticsAcquireRelease);

        exclusive = sh_exclusive;
        exclusiveCount = sh_exclusiveCount;
    }
    ExclusivePrefix ret;
    ret.prefix = exclusive;
    ret.heavyCount = exclusiveCount;
    return ret;
}

void main(void) {
    N = pc.N;
    pivot = g_pivot.pivot;

    if (gl_LocalInvocationID.x == gl_WorkGroupSize.x - 1) {
        sh_partID = atomicAdd(g_states.counter, 1);
    }
    controlBarrier(gl_ScopeWorkgroup, gl_ScopeWorkgroup, gl_StorageSemanticsShared, gl_SemanticsAcquireRelease);
    uint partID = sh_partID;

    const uint base = partID * PARTITION_SIZE + gl_SubgroupID.x * SUBPARTITION_SIZE + gl_SubgroupInvocationID.x;
    //
    WorkgroupAggregate workgroupAggregate = computeLocalPrefixSum(base, N);

    ExclusivePrefix prefix = decoupledLookback(partID, workgroupAggregate);

    for (uint i = 0; i < ROWS; ++i) {
        localExclusiveHeavyCount[i] += prefix.heavyCount;
        localPrefix[i] += prefix.prefix;
    }

    for (uint i = 0; i < ROWS; ++i) {
        const uint index = base + i * SUBGROUP_SIZE;
        if (index < N) {
            const float w = localWeights[i];
            const bool isHeavy = w > pivot;
            uint ix = localExclusiveHeavyCount[i];
            float p;
            if (isHeavy) {
                p = localPrefix[i].x;
            } else {
                p = localPrefix[i].y;
                ix = (N - 1) - (index - ix);
            }
            g_prefix.heavyLight[ix] = p;
            g_partition.heavyLight[ix] = index;
            #ifdef WRITE_PARTITION_ELEMENTS
            g_partitionElements.heavyLight[ix] = w;
            #endif

            if (index == N - 1) {
                uint heavyCount = localExclusiveHeavyCount[i];
                if (isHeavy) {
                    heavyCount += 1;
                }
                g_stat.heavyCount = heavyCount;
            }
        }
    }
}
