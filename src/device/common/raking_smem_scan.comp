#ifndef RAKING_SMEM_SCAN_COMP_GUARD
#define RAKING_SMEM_SCAN_COMP_GUARD

#include "subgroup_scan.comp"


const uint RAKING_THREADS = SUBGROUP_SIZE;
const uint RAKING_STEPS = (gl_WorkGroupSize.x + RAKING_THREADS - 1) / RAKING_THREADS;
const uint SHARED_MEMORY_BANKS = SUBGROUP_SIZE;

#define NO_BANK_CONFLICTS(x) ((x) + (x) / SHARED_MEMORY_BANKS)

shared float raking_scatch[NO_BANK_CONFLICTS(gl_WorkGroupSize.x)];

float raking_smem_inclusive_scan_float(float x) {
    if (gl_WorkGroupSize.x == gl_SubgroupSize.x) {
        return subgroup_inclusive_scan_float(x);
    }
    raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x)] = x;
    barrier();
    if (gl_LocalInvocationID.x < RAKING_THREADS) {
        // Rake only with one subgroup!
        float partial = 0;
        const uint rakingBase = gl_SubgroupInvocationID * RAKING_STEPS;
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            partial += raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)];
        }
        float exclusive = subgroup_exclusive_scan_float(partial);
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            float smem = raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)];
            raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)] = smem + exclusive;
            exclusive += smem;
        }
    }
    barrier();
    x = raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x)];
    return x;
}

// the aggregate in only written by subgroupID == 0
float raking_smem_inclusive_scan_float(float x, out float aggregate) {
    if (gl_WorkGroupSize.x == gl_SubgroupSize.x) {
        return subgroup_inclusive_scan_float(x);
    }
    raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x)] = x;
    barrier();
    if (gl_LocalInvocationID.x < RAKING_THREADS) {
        // Rake only with one subgroup!
        float partial = 0;
        const uint rakingBase = gl_SubgroupInvocationID * RAKING_STEPS;
        #pragma unroll
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            partial += raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)];
        }
        float exclusive = subgroup_exclusive_scan_float(partial, aggregate);
        #pragma unroll
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            float smem = raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)];
            raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)] = smem + exclusive;
            exclusive += smem;
        }
    }
    barrier();
    x = raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x)];
    return x;
}

float raking_smem_exclusive_scan_float(float x) {
    if (gl_WorkGroupSize.x == gl_SubgroupSize.x) {
        return subgroup_exclusive_scan_float(x);
    }
    raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x)] = x;
    barrier();
    if (gl_LocalInvocationID.x < RAKING_THREADS) {
        // Rake only with one subgroup!
        float partial = 0;
        const uint rakingBase = gl_SubgroupInvocationID * RAKING_STEPS;
        #pragma unroll
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            partial += raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)];
        }
        float exclusive = subgroup_exclusive_scan_float(partial);
        #pragma unroll
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            float smem = raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)];
            raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)] = smem + exclusive;
            exclusive += smem;
        }
    }
    barrier();
    x = gl_LocalInvocationID.x > 0 ? raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x - 1)] : 0.0f;
    return x;
}

// the aggregate is only written by subgroupID == 0.
float raking_smem_exclusive_scan_float(float x, out float aggregate) {
    if (gl_WorkGroupSize.x == gl_SubgroupSize.x) {
        return subgroup_exclusive_scan_float(x);
    }
    raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x)] = x;
    barrier();
    if (gl_LocalInvocationID.x < RAKING_THREADS) {
        // Rake only with one subgroup!
        float partial = 0;
        const uint rakingBase = gl_SubgroupInvocationID * RAKING_STEPS;
        #pragma unroll
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            partial += raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)];
        }
        float exclusive = subgroup_exclusive_scan_float(partial, aggregate);
        #pragma unroll
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            float smem = raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)];
            raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)] = smem + exclusive;
            exclusive += smem;
        }
    }
    barrier();
    x = gl_LocalInvocationID.x > 0 ? raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x - 1)] : 0.0f;
    return x;
}

uint raking_smem_inclusive_scan_uint(uint x) {
    if (gl_WorkGroupSize.x == gl_SubgroupSize.x) {
        return subgroup_inclusive_scan_uint(x);
    }
    raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x)] = uintBitsToFloat(x);
    barrier();
    if (gl_LocalInvocationID.x < RAKING_THREADS) {
        // Rake only with one subgroup!
        uint partial = 0;
        const uint rakingBase = gl_SubgroupInvocationID * RAKING_STEPS;
        #pragma unroll
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            partial += floatBitsToUint(raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)]);
        }
        uint exclusive = subgroup_exclusive_scan_uint(partial);
        #pragma unroll
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            uint smem = floatBitsToUint(raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)]);
            raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)] = uintBitsToFloat(smem + exclusive);
            exclusive += smem;
        }
    }
    barrier();
    x = floatBitsToUint(raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x)]);
    return x;
}

// the aggregate in only written by subgroupID == 0
uint raking_smem_inclusive_scan_uint(uint x, out uint aggregate) {
    if (gl_WorkGroupSize.x == gl_SubgroupSize.x) {
        return subgroup_inclusive_scan_uint(x);
    }
    raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x)] = uintBitsToFloat(x);
    barrier();
    if (gl_LocalInvocationID.x < RAKING_THREADS) {
        // Rake only with one subgroup!
        uint partial = 0;
        const uint rakingBase = gl_SubgroupInvocationID * RAKING_STEPS;
        #pragma unroll
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            partial += floatBitsToUint(raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)]);
        }
        uint exclusive = subgroup_exclusive_scan_uint(partial, aggregate);
        #pragma unroll
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            uint smem = floatBitsToUint(raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)]);
            raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)] = uintBitsToFloat(smem + exclusive);
            exclusive += smem;
        }
    }
    barrier();
    x = floatBitsToUint(raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x)]);
    return x;
}

uint raking_smem_exclusive_scan_uint(uint x) {
    if (gl_WorkGroupSize.x == gl_SubgroupSize.x) {
        return subgroup_exclusive_scan_uint(x);
    }
    raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x)] = uintBitsToFloat(x);
    barrier();
    if (gl_LocalInvocationID.x < RAKING_THREADS) {
        // Rake only with one subgroup!
        uint partial = 0;
        const uint rakingBase = gl_SubgroupInvocationID * RAKING_STEPS;
        #pragma unroll
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            partial += floatBitsToUint(raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)]);
        }
        uint exclusive = subgroup_exclusive_scan_uint(partial);
        #pragma unroll
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            uint smem = floatBitsToUint(raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)]);
            raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)] = uintBitsToFloat(smem + exclusive);
            exclusive += smem;
        }
    }
    barrier();
    x = gl_LocalInvocationID.x > 0 ? floatBitsToUint(raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x - 1)]) : 0;
    return x;
}

// the aggregate is only written by subgroupID == 0.
uint raking_smem_exclusive_scan_uint(uint x, out uint aggregate) {
    if (gl_WorkGroupSize.x == gl_SubgroupSize.x) {
        return subgroup_exclusive_scan_uint(x);
    }
    raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x)] = uintBitsToFloat(x);
    barrier();
    if (gl_LocalInvocationID.x < RAKING_THREADS) {
        // Rake only with one subgroup!
        uint partial = 0;
        const uint rakingBase = gl_SubgroupInvocationID * RAKING_STEPS;
        #pragma unroll
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            partial += floatBitsToUint(raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)]);
        }
        uint exclusive = subgroup_exclusive_scan_uint(partial, aggregate);
        #pragma unroll
        for (uint i = 0; i < RAKING_STEPS; ++i) {
            uint smem = floatBitsToUint(raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)]);
            raking_scatch[NO_BANK_CONFLICTS(rakingBase + i)] = uintBitsToFloat(smem + exclusive);
            exclusive += smem;
        }
    }
    barrier();
    x = gl_LocalInvocationID.x > 0 ? floatBitsToUint(raking_scatch[NO_BANK_CONFLICTS(gl_LocalInvocationID.x - 1)]) : 0;
    return x;
}

#endif
